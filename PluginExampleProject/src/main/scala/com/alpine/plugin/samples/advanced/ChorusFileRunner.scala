package com.alpine.plugin.samples.advanced

import com.alpine.plugin.core._
import com.alpine.plugin.core.datasource.OperatorDataSourceManager
import com.alpine.plugin.core.dialog.{ChorusFile, OperatorDialog}
import com.alpine.plugin.core.io._
import com.alpine.plugin.core.io.defaults.IONoneDefault
import com.alpine.plugin.core.spark.{SparkExecutionContext, SparkRuntime}
import com.alpine.plugin.core.utils.{ChorusAPICaller, ChorusUtils}
import com.alpine.plugin.core.visualization.{TextVisualModel, VisualModel, VisualModelFactory}

/**
  * This is a hadoop custom operator that displays the functionality to create a workfile selector
  * dropdown. The custom operator only allows the user to select .txt and .pynb (python notebook)
  * files. It then downloads those files and displays the text of that workfile.
  * If a python notebook was selected it runs the notebook.
  *
  * Finally, the operator creates a new workfile in the workspace
  *
  */
class ChorusFileRunnerSignature extends OperatorSignature[ChorusFileRunnerGUI, ChorusFileRunnerRuntime] {

  override def getMetadata: OperatorMetadata =
    new OperatorMetadata("Sample - Chorus File Dropdown",
      "Plugin Sample - Local",
      Some("Alpine Data"),
      1,
      None,
      None,
      Some("Enter text to show as a tooltip for your operator here. This will appear when a user hovers " +
        "over the operatorâ€™s name in the workflow editor. The best tooltips concisely describe the function" +
        " of the operator and are no more than fifty words."))
}

class ChorusFileRunnerGUI extends OperatorGUINode[IONone, IONone] {

  override def onPlacement(operatorDialog: OperatorDialog,
                           operatorDataSourceManager: OperatorDataSourceManager,
                           operatorSchemaManager: OperatorSchemaManager): Unit = {
    operatorDialog.addChorusFileDropdownBox(id = "file",
      label = "Select a File From the Workspace",
      extensionFilter = Set[String](".ipynb", ".txt"), isRequired = true)
  }


  override def onOutputVisualization(params: OperatorParameters, output: IONone,
                                     visualFactory: VisualModelFactory): VisualModel = {
    TextVisualModel(output.addendum("key").toString)
  }


  override def onInputOrParameterChange(inputSchemas: Map[String, TabularSchema],
                                        params: OperatorParameters,
                                        operatorSchemaManager: OperatorSchemaManager): OperatorStatus =
    super.onInputOrParameterChange(inputSchemas, params, operatorSchemaManager)
}

class ChorusFileRunnerRuntime extends SparkRuntime[IONone, IONone] {

  override def onExecution(context: SparkExecutionContext, input: IONone,
                           params: OperatorParameters, listener: OperatorListener): IONone = {

    // At runtime is is okay to call .get on required Chorus files, since we only run valid operators.
    val chorusFileObject: ChorusFile = params.getChorusFile("file").get

    //retrieve a wrapper for the chorus api from the parameters object
    val chorusAPICaller: ChorusAPICaller = context.chorusAPICaller
    //run notebook
    if (chorusFileObject.extension == ".ipynb") {
      val pythonNotebook = chorusAPICaller.runNotebook(chorusFileObject.id)
      if (pythonNotebook.isSuccess) {
        listener.notifyMessage("The python notebook was last updated by the user on " + pythonNotebook.get.userModifiedAt)
      } else {
        listener.notifyError("The python notebook failed to run: " + pythonNotebook.failed.get.getMessage)
      }
    }
    //download file
    val text = chorusAPICaller.readWorkfileAsText(chorusFileObject.id)

    listener.notifyMessage(
      "The chorus file id is: " + chorusFileObject.id +
      ", the file name is: " + chorusFileObject.name
    )

    //create new workfile in this workspace
    val currentWorkfileId = context.workflowInfo.workflowID
    val tempDir = context.recommendedTempDir

    val newChorusFile = ChorusUtils.writeTextChorusFile("Exported_from_Spark_Op",
      "The is a file that was exported from the runtime class of a Spark operator",
      context,newVersionIfExists = true)

    if (newChorusFile.isSuccess) {
      listener.notifyMessage("The new chorus file: " +
        newChorusFile.get + " was written successfully")
    } else {
      listener.notifyError("Writing new chorus file failed with error: " +
        newChorusFile.failed.get.getMessage)
    }

    IONoneDefault(input.addendum.+("key" -> text))
  }

  override def onStop(context: SparkExecutionContext, listener: OperatorListener): Unit = {}
}